{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d9b8d35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all the necessary libraries\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from qiskit import BasicAer\n",
    "from qiskit.circuit.library import ZZFeatureMap, ZFeatureMap, PauliFeatureMap\n",
    "from qiskit.aqua import QuantumInstance, aqua_globals\n",
    "from qiskit.aqua.algorithms import QSVM\n",
    "from qiskit.aqua.components.multiclass_extensions import AllPairs, OneAgainstRest\n",
    "from qiskit.aqua.utils.dataset_helper import get_feature_dimension\n",
    "from qiskit.aqua.utils import split_dataset_to_data_and_labels, map_label_to_class_name\n",
    "SEED = 1430\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e98bc991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "30\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "# Read text File\n",
    "def read_text_file(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        print(f.read())\n",
    "        \n",
    "\n",
    "path = r\"C:\\Users\\thomas.agnew\\Desktop\\QM workshop\\poster\\pneumonia_dataset\\train_datasets\" # Folder Path\n",
    "os.chdir(path) # Change the directory\n",
    "raw_data_train = []\n",
    "for file in os.listdir(): # iterate through all file\n",
    "    # Check whether file is in text format or not\n",
    "    if file.endswith(\".txt\"):\n",
    "        file_path = f\"{path}\\{file}\"\n",
    "  \n",
    "        # call read text file function\n",
    "        raw_data_train.append(np.genfromtxt(fname=file_path))\n",
    "raw_data_train = np.concatenate((raw_data_train))\n",
    "# raw_data_train = np.concatenate((raw_data_train[0:10],raw_data_train[50:60],raw_data_train[100:110]))\n",
    "    # use the above line if you want to take only slices of the total data set\n",
    "print(len(raw_data_train))\n",
    "        \n",
    "path = r\"C:\\Users\\thomas.agnew\\Desktop\\QM workshop\\poster\\pneumonia_dataset\\test_datasets\" # Folder Path\n",
    "os.chdir(path) # Change the directory\n",
    "raw_data_test = []\n",
    "for file in os.listdir(): # iterate through all file\n",
    "    # Check whether file is in text format or not\n",
    "    if file.endswith(\".txt\"):\n",
    "        file_path = f\"{path}\\{file}\"\n",
    "  \n",
    "        # call read text file function\n",
    "    raw_data_test.append(np.genfromtxt(fname=file_path))\n",
    "raw_data_test = np.concatenate((raw_data_test))\n",
    "# raw_data_test = np.concatenate((raw_data_test[0:10],raw_data_test[50:60],raw_data_test[100:110]))\n",
    "# use the above line if you want to take only slices of the total data set\n",
    "print(len(raw_data_test))\n",
    "\n",
    "raw_data_total = np.concatenate((raw_data_train, raw_data_test))\n",
    "print(len(raw_data_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "73b0e4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the train set: 48\n",
      "Size of the test set: 12\n",
      "[ 26728.28174304   4284.32453881 -12128.52916276  -2382.48791138\n",
      "   2817.90216545  -3610.20727148  -5799.5155579 ]\n",
      "['A', 'A', 'B', 'C', 'A', 'C', 'A', 'A', 'A', 'A', 'C', 'B', 'B', 'C', 'B', 'C', 'B', 'A', 'C', 'C', 'B', 'C', 'B', 'C', 'B', 'B', 'B', 'A', 'B', 'A', 'B', 'C', 'A', 'B', 'A', 'B', 'C', 'A', 'A', 'A', 'C', 'B', 'C', 'A', 'C', 'C', 'C', 'B']\n"
     ]
    }
   ],
   "source": [
    "#processing the data: setting class names to A, B, and C, and splitting into a list of data and a list of classes. \n",
    "\n",
    "data_total=[]\n",
    "class_total=[]\n",
    "for i in range(len(raw_data_total)):\n",
    "    if int(raw_data_total[i][-1])==0:\n",
    "        class_total.append('A')\n",
    "    elif int(raw_data_total[i][-1])==1:\n",
    "        class_total.append('B')\n",
    "    elif int(raw_data_total[i][-1])==2:\n",
    "        class_total.append('C')\n",
    "    data_total.append(raw_data_total[i][0:7])\n",
    "    \n",
    "# split our data into train and test sets using an 80-20 split \n",
    "x_train, x_test, y_train, y_test= train_test_split(\n",
    "    data_total, class_total, test_size=0.2, random_state=SEED, stratify=class_total)\n",
    "\n",
    "print(f'Size of the train set: {len(x_train)}\\nSize of the test set: {len(x_test)}')\n",
    "print((x_train[0]))\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "148d3545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QSVM simulations using more than 2 classes require the data to be input as a dictionary. \n",
    "# the code below is for constructing the dictionary. \n",
    "\n",
    "Dict_train = {}\n",
    "Dict_train.setdefault(\"A\",[]) #initiallized a dictionary key 'A' corresponding to an empty list\n",
    "Dict_train.setdefault(\"B\",[])\n",
    "Dict_train.setdefault(\"C\",[])\n",
    "\n",
    "Dict_test = {}\n",
    "Dict_test.setdefault(\"A\",[])\n",
    "Dict_test.setdefault(\"B\",[])\n",
    "Dict_test.setdefault(\"C\",[])\n",
    "\n",
    "for i in range(len(y_train)):\n",
    "    Dict_train[y_train[i]].append(x_train[i]) #appending to existing key\n",
    "for i in range(len(y_test)):\n",
    "    Dict_test[y_test[i]].append(x_test[i])\n",
    "\n",
    "temp = [Dict_test[k] for k in Dict_test]\n",
    "total_array = np.concatenate(temp)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6dc45df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of repetitions= 1\n",
      "testing_accuracy : 0.08333333333333337\n",
      "test_success_ratio : 0.08333333333333337\n",
      "predicted_labels : [2 1 0 2 0 0 0 0 1 0 1 1]\n",
      "predicted_classes : ['C', 'B', 'A', 'C', 'A', 'A', 'A', 'A', 'B', 'A', 'B', 'B']\n",
      "Number of repetitions= 2\n",
      "testing_accuracy : 0.5\n",
      "test_success_ratio : 0.5\n",
      "predicted_labels : [0 0 1 2 2 2 2 1 2 2 1 2]\n",
      "predicted_classes : ['A', 'A', 'B', 'C', 'C', 'C', 'C', 'B', 'C', 'C', 'B', 'C']\n",
      "Number of repetitions= 3\n",
      "testing_accuracy : 0.33333333333333337\n",
      "test_success_ratio : 0.33333333333333337\n",
      "predicted_labels : [1 0 0 1 1 0 0 1 0 1 0 0]\n",
      "predicted_classes : ['B', 'A', 'A', 'B', 'B', 'A', 'A', 'B', 'A', 'B', 'A', 'A']\n",
      "Number of repetitions= 4\n",
      "testing_accuracy : 0.41666666666666663\n",
      "test_success_ratio : 0.41666666666666663\n",
      "predicted_labels : [2 1 2 0 1 1 0 2 1 1 2 2]\n",
      "predicted_classes : ['C', 'B', 'C', 'A', 'B', 'B', 'A', 'C', 'B', 'B', 'C', 'C']\n",
      "Number of repetitions= 5\n"
     ]
    }
   ],
   "source": [
    "aqua_globals.random_seed = 10598\n",
    "\n",
    "for i in range(1,11,1): #iterates over number of quantum circuit repetitions.\n",
    "    print(\"Number of repetitions=\",i)\n",
    "    backend = BasicAer.get_backend('qasm_simulator') #we use the qasm simulator\n",
    "    feature_map = ZZFeatureMap(feature_dimension=get_feature_dimension(Dict_train),\n",
    "                               reps=i, entanglement='linear') # creating the feature map.\n",
    "    qc = feature_map.assign_parameters(Dict_train[\"A\"][0])\n",
    "\n",
    "    svm = QSVM(feature_map, Dict_train, Dict_test, total_array,\n",
    "               multiclass_extension=OneAgainstRest()) #could also try OneVersusOne()\n",
    "\n",
    "    quantum_instance = QuantumInstance(backend, shots=1024,\n",
    "                                       seed_simulator=aqua_globals.random_seed,\n",
    "                                       seed_transpiler=aqua_globals.random_seed)\n",
    "\n",
    "    result = svm.run(quantum_instance) #running the simulation\n",
    "    for k,v in result.items():\n",
    "        print(f'{k} : {v}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d9f92f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
